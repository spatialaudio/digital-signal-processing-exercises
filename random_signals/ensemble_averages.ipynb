{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Tutorial Digital Signal Processing\n",
    "\n",
    "**Random Signals, Ensemble & Temporal Averages**,\n",
    "Winter Semester 2023/24 (Course #24505)\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/digital-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/digital-signal-processing-exercises\n",
    "\n",
    "Feel free to contact lecturer jacob.thoenes@uni-rostock.de\n",
    "\n",
    "WIP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib as mpl\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import PCG64, Generator\n",
    "from scipy import signal, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_xcorr(x, y):\n",
    "    N, M = len(x), len(y)\n",
    "    kappa = np.arange(N + M - 1) - (M - 1)\n",
    "    ccf = signal.correlate(x, y, mode=\"full\", method=\"auto\")\n",
    "    return kappa, ccf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if True:  # test my_xcorr with simple example\n",
    "    x = np.array([0, 1, 0, 0, 0])\n",
    "    y = np.array([1, 0, 0])\n",
    "    # plot my_xcorr(x, y) vs. my_xcorr(y, x)\n",
    "    plt.figure(figsize=(10, 2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    kappa_xy, ccf_xy = my_xcorr(x, y)\n",
    "    plt.stem(kappa_xy, ccf_xy, basefmt=\"C0:\", linefmt=\"C0\", markerfmt=\"C0o\")\n",
    "    plt.xlabel(r\"$\\kappa$\")\n",
    "    plt.ylabel(r\"$\\varphi_{xy}[\\kappa]$\")\n",
    "    plt.title(r\"cross correlation between x and y, $\\varphi_{xy}[\\kappa]$\")\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    kappa_yx, ccf_yx = my_xcorr(y, x)\n",
    "    plt.stem(kappa_yx, ccf_yx, basefmt=\"C1:\", linefmt=\"C1\", markerfmt=\"C1o\")\n",
    "    plt.xlabel(r\"$\\kappa$\")\n",
    "    plt.ylabel(r\"$\\varphi_{yx}[\\kappa]$\")\n",
    "    plt.title(r\"cross correlation between y and x, $\\varphi_{yx}[\\kappa]$\")\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Order Ensemble Averages\n",
    "\n",
    "For a probability density function (PDF) $p_x(\\theta, k)$ which describes a random process of 'drawing' signal amplitudes $\\theta$ for the $n$-th sample function $x_n[k]$ over time $k$, we can define the following **expectation**\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "E\\{ f(x[k]) \\} = \\int\\limits_{-\\infty}^{\\infty} f(\\theta) \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "E\\{ f(x[k]) \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} f(x_n[k])\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "using the operator or **mapping function** $f(\\cdot)$.\n",
    "\n",
    "Most important are the following **first-order** ensemble averages, also called **univariate** moments, named so, since **one** random process is involved.\n",
    "\n",
    "#### Linear mean / 1st raw moment\n",
    "\n",
    "for mapping function $f(\\theta)=\\theta^1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mu_x[k] = E\\{ x[k] \\} = \\int\\limits_{-\\infty}^{\\infty} \\theta \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "\\mu_x[k] = E\\{ x[k] \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} x_n[k]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Quadratic mean / 2nd raw moment\n",
    "\n",
    "for mapping function $f(\\theta)=\\theta^2$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "E\\{ x^2[k] \\} = \\int\\limits_{-\\infty}^{\\infty} \\theta^2 \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "E\\{ x^2[k] \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} x_n^2[k]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Variance / 2nd centralized moment\n",
    "\n",
    "for mapping function $f(\\theta) = (\\theta - \\mu_x[k])^2$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\sigma_x^2[k] = E\\{ (x[k] - \\mu_x[k])^2 \\} = \\int\\limits_{-\\infty}^{\\infty} (\\theta - \\mu_x[k])^2 \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "\\sigma_x^2[k] = E\\{ (x[k] - \\mu_x[k])^2 \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} (x_n[k] - \\mu_x[k])^2\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "These three moments are generally linked as\n",
    "\\begin{equation}\n",
    "E\\{ x^2[k] \\} = \\mu_x^2[k] + \\sigma_x^2[k],\n",
    "\\end{equation}\n",
    "which reads quadratic mean is linear mean plus variance.\n",
    "\n",
    "\n",
    "For **stationary processes** these ensemble averages are not longer time-dependent, but rather $\\mu_x[k] = \\mu_x = \\mathrm{const}$, etc. holds.\n",
    "This implies that the PDF describing the random process is **not changing over time**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Order Ensemble Averages\n",
    "\n",
    "The **second-order** ensemble averages, also called **bivariate** moments (because **two** random processes are involved) can be derived from\n",
    "\n",
    "\\begin{equation}\n",
    "E\\{ f(x[k_x], y[k_y]) \\} = \\iint\\limits_{-\\infty}^{\\infty} f(\\theta_x, \\theta_y) \\, p_{xy}(\\theta_x, \\theta_y, k_x, k_y) \\, \\mathrm{d}\\theta_x\\, \\mathrm{d}\\theta_y\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "E\\{ f(x[k_x], y[k_y]) \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} f(x_n[k_x], y_n[k_y])\n",
    "\\end{equation}\n",
    "\n",
    "using appropriate **mapping functions** $f(\\cdot)$.\n",
    "\n",
    "For **stationary processes** only the difference $\\kappa = k_x - k_y$ is relevant as bivariate PDF\n",
    "\\begin{equation}\n",
    "p_{xy}(\\theta_x, \\theta_y, k_x, k_y) = p_{xy}(\\theta_x, \\theta_y, \\kappa).\n",
    "\\end{equation}\n",
    "\n",
    "For **stationary processes** two important cases lead to fundamental tools for random signal processing:\n",
    "\n",
    "- Case 1: $\\kappa = 0$, i.e. $k = k_x = k_y$\n",
    "- Case 2: $\\kappa \\neq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1 for Stationary Process\n",
    "\n",
    "The general linear mapping functions\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{for raw (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y)=\\theta_x^1 \\cdot \\theta_y^1,\\\\\n",
    "\\text{for centralized (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y) = (\\theta_x - \\mu_x[k_x])^1 \\cdot (\\theta_y - \\mu_y[k_y])^1\\\\\n",
    "\\text{for standardized (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y) = \\left(\\frac{\\theta_x - \\mu_x[k_x]}{\\sigma_x[k_x]}\\right)^1 \\cdot \\left(\\frac{\\theta_y - \\mu_y[k_y]}{\\sigma_y[k_y]}\\right)^1.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "simplify under the assumption of stationary processes and considering case 1: $\\kappa=0$, i.e. $k = k_x = k_y$.\n",
    "The resulting expectations $E\\{\\cdot\\}$ then are\n",
    "\n",
    "- the **raw** (1,1)-bivariate moment known as **cross-power** $\\mathrm{P}_{xy}$\n",
    "- the **centralized** (1,1)-bivariate moment known as **co-variance** $\\sigma_{xy}$\n",
    "- the **standardized** (1,1)-bivariate moment known as **correlation coefficient** $\\rho_{xy}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2 for Stationary Process\n",
    "\n",
    "For $\\kappa = k_x - k_y \\neq 0$ the raw and centralized moments are of special importance:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mathrm{raw:}\\qquad&\\varphi_{xy}[k_x, k_y] = \\varphi_{xy}[\\kappa] = E\\{ x[k] \\cdot y[k-\\kappa]\\} = E\\{ x[k+\\kappa] \\cdot y[k]\\}\\\\\n",
    "\\mathrm{centralized:}\\qquad&\\psi_{xy}[\\kappa] = \\varphi_{xy}[\\kappa] - \\mu_x \\mu_y\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "The raw moment is known as **cross-correlation** function $\\varphi_{xy}[\\kappa]$, the centralized moment is known as **cross-covariance** function $\\psi_{xy}[\\kappa]$.\n",
    "\n",
    "If for the second process $y$ we consider the process $x$, so that $x[k] = y[k]$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mathrm{raw:}\\qquad&\\varphi_{xx}[\\kappa] = E\\{ x[k] \\cdot x[k-\\kappa]\\} = E\\{ x[k+\\kappa] \\cdot x[k]\\}\\\\\n",
    "\\mathrm{centralized:}\\qquad&\\psi_{xx}[\\kappa] = \\varphi_{xx}[\\kappa] - \\mu^2_x\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "the so called **auto-correlation** function $\\varphi_{xx}[\\kappa]$ and **auto-covariance** function $\\psi_{xx}[\\kappa]$ are obtained.\n",
    "\n",
    "The **auto- and cross-correlation** functions are of fundamental importance for random signal processing, as these are **linked to LTI system signal processing**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergodic Processes\n",
    "\n",
    "Averaging over time is equal to ensemble averages:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ f(x_n[k], x_n[k-\\kappa_1], x_n[k-\\kappa_2], \\dots) } = E\\{  f(x[k], x[k-\\kappa_1], x[k-\\kappa_2], \\dots)  \\} \\;\\; \\forall n.\n",
    "\\end{equation}\n",
    "\n",
    "## Wide-Sense Ergodic\n",
    "\n",
    "ergodicity holds for linear mapping\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ x_n[k] \\cdot x_n[k-\\kappa] } = E\\{  x[k] \\cdot x[k-\\kappa]  \\} \\;\\; \\forall n\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ x_n[k] } = E\\{  x[k] \\} \\;\\; \\forall n.\n",
    "\\end{equation}\n",
    "\n",
    "## Important Temporal Averages\n",
    "\n",
    "The linear mean as temporal average of the $n$-th sample function $x_n[k]$ is for instance given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{x_n[k]} = \\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} x_n[k].\n",
    "\\end{equation}\n",
    "\n",
    "Furthermore:\n",
    "\n",
    "The **quadratic mean** from simple quadratic mapping is given as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} x^2_n[k],\n",
    "\\end{equation}\n",
    "\n",
    "the **variance** is given as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} (x_n[k]-\\overline{x_n[k]})^2,\n",
    "\\end{equation}\n",
    "\n",
    "the **cross-correlation** as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k=-K}^{K} x[k] \\cdot y[k-\\kappa],\n",
    "\\end{equation}\n",
    "\n",
    "and the **auto- correlation** as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k=-K}^{K} x[k] \\cdot x[k-\\kappa].\n",
    "\\end{equation}\n",
    "\n",
    "These equations hold for power signals, i.e. the summation yields a finite value.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Histogram as PDF Estimate, First-Order Ensemble Averages\n",
    "\n",
    "of Normal distribution process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducible results\n",
    "seed = 1234\n",
    "stats.norm.random_state = Generator(PCG64(seed))\n",
    "\n",
    "# create random process based on normal distribution\n",
    "Ns = 2**10  # number of sample functions for e.g. time instance k=0\n",
    "loc, scale = 5, 3  # mu, sigma\n",
    "\n",
    "theta = np.arange(-15, 25, 0.01)  # amplitudes for plotting PDF\n",
    "# random process object with normal PDF\n",
    "rv = stats.norm(loc=loc, scale=scale)\n",
    "# get random data from sample functions\n",
    "x = stats.norm.rvs(loc=loc, scale=scale, size=Ns)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "hist_estimate = ax.hist(\n",
    "    x,\n",
    "    bins=\"auto\",\n",
    "    density=True,\n",
    "    histtype=\"bar\",\n",
    "    color=\"C0\",\n",
    "    alpha=0.5,\n",
    "    label=\"histogram\",\n",
    ")\n",
    "ax.plot(theta, rv.pdf(theta), \"C0-\", lw=2, label=\"pdf\")\n",
    "ax.set_xlabel(r\"$\\theta$\")\n",
    "ax.set_ylabel(r\"$\\hat{p}_x(\\theta,k=0)$\")\n",
    "ax.set_title(\"normalized histogram = PDF estimate\")\n",
    "ax.set_xlim(-15, 25)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# get histogram data from ax.hist()\n",
    "edges = hist_estimate[1]\n",
    "freq = hist_estimate[0]\n",
    "\n",
    "# simple ensemble averages by numeric integration\n",
    "# over histogram data as a simple estimate of the pdf\n",
    "theta_num = edges[:-1]\n",
    "dtheta = np.diff(edges)\n",
    "mu = np.sum(theta_num * freq * dtheta)  # mu estimate\n",
    "qm = np.sum(theta_num**2 * freq * dtheta)  # quadratic mean estimate\n",
    "sig2 = np.sum((theta_num - mu) ** 2 * freq * dtheta)  # sigma^2 estimate\n",
    "print(\n",
    "    \"ideal   ensemble average: mu = %5.2f, mu^2 = %5.2f, sigma^2 = %5.2f, mu^2 + sigma^2 = %5.2f\"\n",
    "    % (loc, loc**2, scale**2, loc**2 + scale**2)\n",
    ")\n",
    "print(\n",
    "    \"numeric ensemble average: mu = %5.2f, mu^2 = %5.2f, sigma^2 = %5.2f, mu^2 + sigma^2 = %5.2f\"\n",
    "    % (mu, mu**2, sig2, qm)\n",
    ")\n",
    "print(\"ideal sigma = %5.2f, numeric sigma = %5.2f\" % (scale, np.sqrt(sig2)))\n",
    "\n",
    "# We should think about:\n",
    "\n",
    "# play around with Ns: what happens if you increase / decrease Ns in terms of\n",
    "# the histogram plot and the estimated first-order ensemble averages\n",
    "\n",
    "# play around with loc==mean, scale==sigma: how is the histogram and pdf\n",
    "# changed, what tells us the standard deviation in terms of the area under the\n",
    "# pdf\n",
    "\n",
    "# ax.hist(x,...) is a handy tool for plotting and getting histogram data\n",
    "# we have chosen bins='auto', density=True. Calculating these data is not\n",
    "# trivial, at least if the histogram should represent the data in pdf-like\n",
    "# form as here. So we should make sure that we are aware of the concepts for\n",
    "# so called kernel density estimation\n",
    "# Nice programming task would be manual histogram calc and plot for\n",
    "# bins=100 and density=False, i.e. a classical manual histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Histogram of Gaussian Noise, Cosine and Rectangular Signal\n",
    "\n",
    "Here we use the numpy histogram with fixed number of bins and really the histogram mode rather than the density mode.\n",
    "\n",
    "We here do not strictly deal with random sample functions (for the cosine and rect), but with amplitude values over time. We do this for practical purpose however, since it is nice to get an idea what a histogram looks like for known signals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = 200\n",
    "\n",
    "Ns = 10000  # number of sample function\n",
    "Nt = 1  # number of time steps per sample function\n",
    "\n",
    "# normal pdf\n",
    "x = np.random.normal(loc=0, scale=1, size=[Ns, 1])\n",
    "pdf, edges = np.histogram(x[:, 0], bins=bins, density=False)\n",
    "plt.plot(edges[:-1], pdf, \"o-\", ms=5, label=r\"gaussian PDF, $\\sigma=1$\")\n",
    "\n",
    "# cosine signal with peak amplitude 1\n",
    "x = np.cos(1 * 2 * np.pi / Ns * np.arange(0, Ns))\n",
    "pdf, edges = np.histogram(x, bins=bins, density=False)\n",
    "plt.plot(edges[:-1], pdf, \"o-\", ms=5, label=\"cos\")\n",
    "\n",
    "# rect signal with amplitude 1.5\n",
    "x = np.cos(1 * 2 * np.pi / Ns * np.arange(0, Ns))\n",
    "x[x >= 0] = +1.5\n",
    "x[x < 0] = -1.5\n",
    "pdf, edges = np.histogram(x, bins=bins, density=False)\n",
    "plt.plot(edges[:-1], pdf, \"o-\", ms=5, label=\"rect\")\n",
    "\n",
    "plt.ylim(0, 500)\n",
    "plt.xlabel(r\"$\\theta$\")\n",
    "plt.ylabel(r\"histogram($\\theta$)\")\n",
    "plt.title(\"frequency (Häufigkeit) of the signal amplitudes within 200 bins\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# We should think about:\n",
    "\n",
    "# what happens if we apply a DC component to the cos and rect signal,\n",
    "# e.g. x += 1\n",
    "\n",
    "# we should able to predict the green histogram values exactly, how should\n",
    "# plt.ylim(0, ???) altered to plot the histogram for the rect more nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Example: Higher-Order Ensemble Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two random processes based on normal distribution\n",
    "Ns = 2**10  # number of sample functions at certain time instant k\n",
    "Nt = 1  # number of time steps per sample function\n",
    "np.random.seed(1)\n",
    "\n",
    "# 1st process:\n",
    "locx, scalex = 1, 3\n",
    "x = np.random.normal(loc=locx, scale=scalex, size=[Ns, Nt])\n",
    "\n",
    "# 2nd process:\n",
    "locy, scaley = 2, 4\n",
    "y = np.random.normal(loc=locy, scale=scaley, size=[Ns, Nt])\n",
    "\n",
    "# check the case y = x, then: crosspower->auto power, covariance -> variance, correlation coefficient rho=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosspower = np.mean(x * y)\n",
    "covariance = np.mean((x - np.mean(x)) * (y - np.mean(y)))\n",
    "rho = np.mean((x - np.mean(x)) / np.std(x) * (y - np.mean(y)) / np.std(y))\n",
    "print(\n",
    "    \"crosspower = %4.3f, covariance = %4.3f,  correlation coefficient rho = %4.3f\"\n",
    "    % (crosspower, covariance, rho)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Average vs. Temporal Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random process based on normal distribution\n",
    "Ns = 4000  # number of samples to set up an ensemble\n",
    "Nt = 15000  # number of time steps to set up 'ensemble over time'-characteristics\n",
    "np.random.seed(1)\n",
    "\n",
    "s = np.arange(Ns)  # ensemble index (s to indicate sample function)\n",
    "t = np.arange(Nt)  # time index\n",
    "\n",
    "loc, scale = 5, 3  # mu, sigma\n",
    "x = np.random.normal(loc=loc, scale=scale, size=[Ns, Nt])\n",
    "\n",
    "# we check the three cases:\n",
    "# 1. simulate an ergodic process, i.e. ensemble average == temporal average\n",
    "case_str = \"x\"\n",
    "# 2./3. very simple simulation of non-stationary process by changing the mean\n",
    "case_str = \"cos_s\"  # add cosine over ensemble equally for all time instances\n",
    "# case_str = 'cos_t'  # add cosine over time equally for all ensembles\n",
    "\n",
    "# the plots nicely show the concept of\n",
    "# temporal average (left column) vs. ensemble average (right column)\n",
    "# we make sure to understand it with the\n",
    "# cos-like patterns either over samples or over time instances\n",
    "\n",
    "if case_str == \"x\":  # use x directly == ergodic process\n",
    "    tmp = 1  # dummy variable since nothing to do here\n",
    "elif case_str == \"cos_s\":  # add cosine over ensemble equally for all time instances\n",
    "    tmp = 2 * np.cos(2 * 2 * np.pi / Ns * np.arange(0, Ns)) + 5\n",
    "    x = x + np.transpose(np.tile(tmp, (Nt, 1)))\n",
    "elif case_str == \"cos_t\":  # add cosine over time equally for all ensembles\n",
    "    tmp = 2 * np.cos(2 * 2 * np.pi / Nt * np.arange(0, Nt)) + 5\n",
    "    x = x + np.tile(tmp, (Ns, 1))\n",
    "\n",
    "fig, axs = plt.subplots(4, 2, figsize=(9, 13))\n",
    "# plot signals\n",
    "for i in range(4):\n",
    "    axs[0, 0].plot(x[:, i], s, label=\"time index \" + str(i))\n",
    "    axs[0, 1].plot(t, x[i, :], label=\"ensemble index \" + str(i))\n",
    "# plot means\n",
    "axs[1, 0].plot(np.mean(x, axis=1), s)\n",
    "axs[1, 1].plot(t, np.mean(x, axis=0))\n",
    "axs[1, 0].plot([loc, loc], [0, Ns])\n",
    "axs[1, 1].plot([0, Nt], [loc, loc])\n",
    "# plot variance\n",
    "axs[2, 0].plot(np.var(x, axis=1), s)\n",
    "axs[2, 1].plot(t, np.var(x, axis=0))\n",
    "axs[2, 0].plot([scale**2, scale**2], [0, Ns])\n",
    "axs[2, 1].plot([0, Nt], [scale**2, scale**2])\n",
    "# plot quadratic mean\n",
    "axs[3, 0].plot(np.mean(x**2, axis=1), s)\n",
    "axs[3, 1].plot(t, np.mean(x**2, axis=0))\n",
    "axs[3, 0].plot([loc**2 + scale**2, loc**2 + scale**2], [0, Ns])\n",
    "axs[3, 1].plot([0, Nt], [loc**2 + scale**2, loc**2 + scale**2])\n",
    "# labeling\n",
    "axs[3, 1].set_xlabel(\"time index\")\n",
    "for i in range(4):\n",
    "    # axs[i,1].set_xlabel('time index')\n",
    "    axs[i, 0].set_ylabel(\"ensemble index\")\n",
    "    for j in range(2):\n",
    "        axs[i, j].grid(True)\n",
    "axs[0, 0].set_title(r\"temporal average for fixed ensemble index\")\n",
    "axs[0, 1].set_title(r\"ensemble average for fixed time instance\")\n",
    "for i in range(2):\n",
    "    axs[0, i].legend(loc=\"upper left\")\n",
    "    axs[1, i].set_title(r\"linear mean $E\\{x\\} = \\mu$\")\n",
    "    axs[2, i].set_title(r\"variance  $E\\{(x -E\\{x\\} )^2\\} = \\sigma^2$\")\n",
    "    axs[3, i].set_title(r\"quadratic mean $E\\{x^2\\} = \\mu^2+\\sigma^2$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-Order Temporal Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two random processes based on normal distribution\n",
    "Ns = 1  # number of sample functions at certain time instant k\n",
    "Nt = 2**7  # number of time steps per sample function\n",
    "np.random.seed(1)\n",
    "\n",
    "# 1st process:\n",
    "locx, scalex = 1, 3\n",
    "x = np.random.normal(loc=locx, scale=scalex, size=[Ns, Nt])\n",
    "\n",
    "# 2nd process:\n",
    "locy, scaley = 2, 4\n",
    "y = np.random.normal(loc=locy, scale=scaley, size=[Ns, Nt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Correlation Function (ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :], x[0, :])\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"Auto Correlation Function $\\varphi_{xx}[\\kappa]$\")\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :], y[0, :])\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"Auto Correlation Function $\\varphi_{yy}[\\kappa]$\")\n",
    "plt.grid(True)\n",
    "\n",
    "# check the axial symmetry, why is the peak always at kappa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Correlation Function (CCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :], y[0, :])\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"Cross Correlation Function $\\varphi_{xy}[\\kappa]=\\phi_{yx}[-\\kappa]$\")\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :], x[0, :])\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"Cross Correlation Function $\\varphi_{yx}[\\kappa]=\\phi_{xy}[-\\kappa]$\")\n",
    "plt.grid(True)\n",
    "\n",
    "# check the mirrored versions and how they related wrt kappa, x,y-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto Covariance Function\n",
    "\n",
    "typically no symbol in equations and no abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :] - np.mean(x[0, :]), x[0, :] - np.mean(x[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"AutoCov$_{xx}[\\kappa]$\")\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :] - np.mean(y[0, :]), y[0, :] - np.mean(y[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"AutoCov$_{yy}[\\kappa]$\")\n",
    "plt.grid(True)\n",
    "\n",
    "# check the axial symmetry, why is the peak always at kappa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Covariance Function\n",
    "\n",
    "typically no symbol in equations and no abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :] - np.mean(x[0, :]), y[0, :] - np.mean(y[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"CrossCov$_{xy}[\\kappa]$=CrossCov$_{yx}[-\\kappa]$\")\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :] - np.mean(y[0, :]), x[0, :] - np.mean(x[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt=\"C0:\")\n",
    "plt.xlabel(r\"$\\kappa$\")\n",
    "plt.title(r\"CrossCov$_{yx}[\\kappa]$=CrossCov$_{xy}[-\\kappa]$\")\n",
    "plt.grid(True)\n",
    "\n",
    "# check the mirrored versions and how they related wrt kappa, x,y-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Copyright**\n",
    "\n",
    "The notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources). Feel free to use the notebooks for your own purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT). Please attribute the work as follows: *Frank Schultz, Digital Signal Processing - A Tutorial Featuring Computational Examples* with the URL https://github.com/spatialaudio/digital-signal-processing-exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
