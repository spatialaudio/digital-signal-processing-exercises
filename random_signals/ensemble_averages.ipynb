{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sascha Spors,\n",
    "Professorship Signal Theory and Digital Signal Processing,\n",
    "Institute of Communications Engineering (INT),\n",
    "Faculty of Computer Science and Electrical Engineering (IEF),\n",
    "University of Rostock,\n",
    "Germany\n",
    "\n",
    "# Tutorial Digital Signal Processing\n",
    "\n",
    "**Random Signals, Ensemble & Temporal Averages**,\n",
    "Winter Semester 2021/22 (Course #24505)\n",
    "\n",
    "- lecture: https://github.com/spatialaudio/digital-signal-processing-lecture\n",
    "- tutorial: https://github.com/spatialaudio/digital-signal-processing-exercises\n",
    "\n",
    "Feel free to contact lecturer frank.schultz@uni-rostock.de\n",
    "\n",
    "WIP..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "from matplotlib import pyplot as plt\n",
    "from numpy.random import Generator, PCG64\n",
    "from scipy import signal\n",
    "from scipy import stats\n",
    "\n",
    "\n",
    "def my_xcorr(x, y):\n",
    "    N, M = len(x), len(y)\n",
    "    kappa = np.arange(N+M-1) - (M-1)\n",
    "    ccf = signal.correlate(x, y, mode='full', method='auto')\n",
    "    return kappa, ccf\n",
    "\n",
    "\n",
    "if True:  # test my_xcorr with simple example\n",
    "    x = np.array([0, 1, 0, 0, 0])\n",
    "    y = np.array([1, 0, 0])\n",
    "    # plot my_xcorr(x, y) vs. my_xcorr(y, x)\n",
    "    plt.figure(figsize=(9, 2))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    kappa_xy, ccf_xy = my_xcorr(x, y)  \n",
    "    plt.stem(kappa_xy, ccf_xy, basefmt='C0:', use_line_collection=True)\n",
    "    plt.xlabel(r'$\\kappa$')\n",
    "    plt.ylabel(r'$\\varphi_{xy}[\\kappa]$')\n",
    "    plt.title('cross correlation between x and y')\n",
    "    plt.grid(True)\n",
    "    plt.subplot(1, 2, 2)\n",
    "    kappa_yx, ccf_yx = my_xcorr(y, x)\n",
    "    plt.stem(kappa_yx, ccf_yx, basefmt='C0:', use_line_collection=True)\n",
    "    plt.xlabel(r'$\\kappa$')\n",
    "    plt.ylabel(r'$\\varphi_{yx}[\\kappa]$')\n",
    "    plt.title('cross correlation between y and x')\n",
    "    plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First-Order Ensemble Averages\n",
    "\n",
    "For a probability density function (PDF) $p_x(\\theta, k)$ that describes a random process of 'drawing' signal amplitudes $\\theta$ for $n$-th sample function $x_n[k]$ over time $k$, we can define the following **expectation**\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "E\\{ f(x[k]) \\} = \\int\\limits_{-\\infty}^{\\infty} f(\\theta) \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "E\\{ f(x[k]) \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} f(x_n[k])\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "using the operator or **mapping function** $f(\\cdot)$.\n",
    "\n",
    "Most important are the following **first-order** ensemble averages, also called **univariate** moments, named since **one** random process is involved.\n",
    "\n",
    "#### Linear mean / 1st raw moment\n",
    "\n",
    "for $f(\\theta)=\\theta^1$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mu_x[k] = E\\{ x[k] \\} = \\int\\limits_{-\\infty}^{\\infty} \\theta \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "\\mu_x[k] = E\\{ x[k] \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} x_n[k]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Quadratic mean / 2nd raw moment\n",
    "\n",
    "for $f(\\theta)=\\theta^2$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "E\\{ x^2[k] \\} = \\int\\limits_{-\\infty}^{\\infty} \\theta^2 \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "E\\{ x^2[k] \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} x_n^2[k]\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "#### Variance / 2nd centralized moment\n",
    "\n",
    "for $f(\\theta) = (\\theta - \\mu_x[k])^2$\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\sigma_x^2[k] = E\\{ (x[k] - \\mu_x[k])^2 \\} = \\int\\limits_{-\\infty}^{\\infty} (\\theta - \\mu_x[k])^2 \\, p_x(\\theta, k) \\, \\mathrm{d}\\theta\\\\\n",
    "\\sigma_x^2[k] = E\\{ (x[k] - \\mu_x[k])^2 \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} (x_n[k] - \\mu_x[k])^2\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "These three moments are generally linked as\n",
    "\\begin{equation}\n",
    "E\\{ x^2[k] \\} = \\mu_x^2[k] + \\sigma_x^2[k].\n",
    "\\end{equation}\n",
    "\n",
    "For **stationary processes** these ensemble averages are not longer time-dependent, but rather $\\mu_x[k] = \\mu_x = \\mathrm{const}$, etc. holds.\n",
    "This implies that the PDF is not changing over time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Second-Order Ensemble Averages\n",
    "\n",
    "The **second-order** ensemble averages, also called **bivariate** moments (**two** random processes are involved) can be derived from\n",
    "\n",
    "\\begin{equation}\n",
    "E\\{ f(x[k_x], y[k_y]) \\} = \\iint\\limits_{-\\infty}^{\\infty} f(\\theta_x, \\theta_y) \\, p_{xy}(\\theta_x, \\theta_y, k_x, k_y) \\, \\mathrm{d}\\theta_x\\, \\mathrm{d}\\theta_y\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "E\\{ f(x[k_x], y[k_y]) \\} = \\lim_{N \\to \\infty} \\frac{1}{N} \\sum_{n=0}^{N-1} f(x_n[k_x], y_n[k_y])\n",
    "\\end{equation}\n",
    "\n",
    "using appropriate **mapping functions** $f(\\cdot)$.\n",
    "\n",
    "For **stationary processes** only the difference $\\kappa = k_x - k_y$ is relevant as bivariate PDF\n",
    "\\begin{equation}\n",
    "p_{xy}(\\theta_x, \\theta_y, k_x, k_y) = p_{xy}(\\theta_x, \\theta_y, \\kappa).\n",
    "\\end{equation}\n",
    "\n",
    "For **stationary processes** two important cases lead to fundamental tools for random signal processing:\n",
    "\n",
    "1. $\\kappa = 0$, i.e. $k = k_x = k_y$\n",
    "2. $\\kappa \\neq 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 1\n",
    "\n",
    "The general linear mappings\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\text{for raw (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y)=\\theta_x^1 \\cdot \\theta_y^1,\\\\\n",
    "\\text{for centralized (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y) = (\\theta_x - \\mu_x[k_x])^1 \\cdot (\\theta_y - \\mu_y[k_y])^1\\\\\n",
    "\\text{for standardized (1,1)-bivariate moment:} \\qquad & f(\\theta_x, \\theta_y) = \\left(\\frac{\\theta_x - \\mu_x[k_x]}{\\sigma_x[k_x]}\\right)^1 \\cdot \\left(\\frac{\\theta_y - \\mu_y[k_y]}{\\sigma_y[k_y]}\\right)^1.\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "simplify under the assumption of stationary processes and considering $\\kappa=0$, i.e. $k = k_x = k_y$.\n",
    "The resulting expectations $E\\{\\cdot\\}$ are\n",
    "\n",
    "- the raw (1,1)-bivariate moment, known as cross-power $\\mathrm{P}_{xy}$\n",
    "- the centralized (1,1)-bivariate moment, known as co-variance $\\sigma_{xy}$\n",
    "- the standardized (1,1)-bivariate moment, known as correlation coefficient $\\rho_{xy}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case 2\n",
    "\n",
    "For $\\kappa = k_x - k_y \\neq 0$ the raw and centralized moments are of special importance:\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mathrm{raw:}\\qquad&\\varphi_{xy}[k_x, k_y] = \\varphi_{xy}[\\kappa] = E\\{ x[k] \\cdot y[k-\\kappa]\\} = E\\{ x[k+\\kappa] \\cdot y[k]\\}\\\\\n",
    "\\mathrm{centralized:}\\qquad&\\psi_{xy}[\\kappa] = \\varphi_{xy}[\\kappa] - \\mu_x \\mu_y\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "\n",
    "The raw moment is known as **cross-correlation** function $\\varphi_{xy}[\\kappa]$, the centralized moment is known as **cross-covariance** function $\\psi_{xy}[\\kappa]$.\n",
    "\n",
    "If for the second process $y$ the process $x$ is considered as\n",
    "\n",
    "\\begin{equation}\n",
    "\\begin{split}\n",
    "\\mathrm{raw:}\\qquad&\\varphi_{xx}[\\kappa] = E\\{ x[k] \\cdot x[k-\\kappa]\\} = E\\{ x[k+\\kappa] \\cdot x[k]\\}\\\\\n",
    "\\mathrm{centralized:}\\qquad&\\psi_{xx}[\\kappa] = \\varphi_{xx}[\\kappa] - \\mu^2_x\n",
    "\\end{split}\n",
    "\\end{equation}\n",
    "the so called **auto-correlation** function $\\varphi_{xx}[\\kappa]$ and **auto-covariance** function $\\psi_{xx}[\\kappa]$ are obtained.\n",
    "\n",
    "The auto- and cross-correlation functions are of fundamental importance for random signal processing, as these are linked to LTI systems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ergodic Processes\n",
    "\n",
    "Averaging over time is equal to ensemble averages:\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ f(x_n[k], x_n[k-\\kappa_1], x_n[k-\\kappa_2], \\dots) } = E\\{  f(x[k], x[k-\\kappa_1], x[k-\\kappa_2], \\dots)  \\} \\;\\; \\forall n.\n",
    "\\end{equation}\n",
    "\n",
    "## Wide-Sense Ergodic\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ x_n[k] \\cdot x_n[k-\\kappa] } = E\\{  x[k] \\cdot x[k-\\kappa]  \\} \\;\\; \\forall n\n",
    "\\end{equation}\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{ x_n[k] } = E\\{  x[k] \\} \\;\\; \\forall n.\n",
    "\\end{equation}\n",
    "\n",
    "## Important Temporal Averages\n",
    "\n",
    "The linear mean as temporal average of the $n$-th sample function $x_n[k]$ is for instance given by\n",
    "\n",
    "\\begin{equation}\n",
    "\\overline{x_n[k]} = \\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} x_n[k].\n",
    "\\end{equation}\n",
    "\n",
    "Furthermore, the quadratic mean from simple quadratic mapping is given as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} x^2_n[k],\n",
    "\\end{equation}\n",
    "\n",
    "the variance is given as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k = -K}^{K} (x_n[k]-\\overline{x_n[k]})^2,\n",
    "\\end{equation}\n",
    "\n",
    "the cross-correlation as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k=-K}^{K} x[k] \\cdot y[k-\\kappa],\n",
    "\\end{equation}\n",
    "\n",
    "and the auto- correlation as\n",
    "\\begin{equation}\n",
    "\\lim_{K \\to \\infty} \\frac{1}{2K + 1} \\sum_{k=-K}^{K} x[k] \\cdot x[k-\\kappa].\n",
    "\\end{equation}\n",
    "\n",
    "These equations hold for power signals. Virtually all random signals are power signals rather than energy signals. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Histogram as PDF Estimate, First-Order Ensemble Averages\n",
    "\n",
    "of Normal distribution process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set seed for reproducible results\n",
    "seed = 1234\n",
    "stats.norm.random_state = Generator(PCG64(seed))\n",
    "\n",
    "# create random process based on normal distribution\n",
    "Ns = 2**10  # number of sample functions for e.g. time instance k=0\n",
    "loc, scale = 5, 3  # mu, sigma\n",
    "\n",
    "theta = np.arange(-15, 25, 0.01)  # amplitudes for plotting PDF\n",
    "# random process object with normal PDF\n",
    "rv = stats.norm(loc=loc, scale=scale)\n",
    "# get random data from sample functions\n",
    "x = stats.norm.rvs(loc=loc, scale=scale, size=Ns)\n",
    "\n",
    "# plot\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "hist_estimate = ax.hist(x, bins='auto', density=True, histtype='bar',\n",
    "                        color='C0', alpha=0.5, label='histogram')\n",
    "ax.plot(theta, rv.pdf(theta), 'C0-', lw=2, label='pdf')\n",
    "ax.set_xlabel(r'$\\theta$')\n",
    "ax.set_ylabel(r'$\\hat{p}_x(\\theta,k=0)$')\n",
    "ax.set_title('normalized histogram = PDF estimate')\n",
    "ax.set_xlim(-15, 25)\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "# get histogram data from ax.hist()\n",
    "edges = hist_estimate[1]\n",
    "freq = hist_estimate[0]\n",
    "\n",
    "# simple ensemble averages by numeric integration\n",
    "# over histogram data as a simple estimate of the pdf\n",
    "theta_num = edges[:-1]\n",
    "dtheta = np.diff(edges)\n",
    "mu = np.sum(theta_num * freq * dtheta)  # mu estimate\n",
    "qm = np.sum(theta_num**2 * freq * dtheta)  # quadratic mean estimate\n",
    "sig2 = np.sum((theta_num-mu)**2 * freq * dtheta)  # sigma^2 estimate\n",
    "print('ideal   ensemble average: mu = %5.2f, mu^2 = %5.2f, sigma^2 = %5.2f, mu^2 + sigma^2 = %5.2f' %\n",
    "      (loc, loc**2, scale**2, loc**2+scale**2))\n",
    "print('numeric ensemble average: mu = %5.2f, mu^2 = %5.2f, sigma^2 = %5.2f, mu^2 + sigma^2 = %5.2f' %\n",
    "      (mu, mu**2, sig2, qm))\n",
    "print('ideal sigma = %5.2f, numeric sigma = %5.2f' % (scale, np.sqrt(sig2)))\n",
    "\n",
    "# We should think about:\n",
    "\n",
    "# play around with Ns: what happens if you increase / decrease Ns in terms of\n",
    "# the histogram plot and the estimated first-order ensemble averages\n",
    "\n",
    "# play around with loc==mean, scale==sigma: how is the histogram and pdf\n",
    "# changed, what tells us the standard deviation in terms of the area under the\n",
    "# pdf\n",
    "\n",
    "# ax.hist(x,...) is a handy tool for plotting and getting histogram data\n",
    "# we have chosen bins='auto', density=True. Calculating these data is not\n",
    "# trivial, at least if the histogram should represent the data in pdf-like\n",
    "# form as here. So we should make sure that we are aware of the concepts for\n",
    "# so called kernel density estimation\n",
    "# Nice programming task would be manual histogram calc and plot for\n",
    "# bins=100 and density=False, i.e. a classical manual histogram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Histogram of Gaussian Noise, Cosine and Rectangular Signal\n",
    "\n",
    "here we use the numpy histogram with fixed number of bins and histogram mode rather than density mode\n",
    "\n",
    "we don't strictly deal here with random sample functions, but with a amplitude values over time, but it nice to get an idea what a histogram looks like for known signals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = 10000  # number of sample function\n",
    "Nt = 1  # number of time steps per sample function\n",
    "\n",
    "# normal pdf\n",
    "x = np.random.normal(loc=0, scale=1, size=[Ns, 1])\n",
    "pdf, edges = np.histogram(x[:, 0], bins=200, density=False)\n",
    "plt.plot(edges[:-1], pdf, 'o-', ms=5, label=r'gaussian PDF, $\\sigma=1$')\n",
    "\n",
    "# cosine signal with peak amplitude 1\n",
    "x = np.cos(1 * 2*np.pi/Ns*np.arange(0, Ns))\n",
    "pdf, edges = np.histogram(x, bins=200, density=False)\n",
    "plt.plot(edges[:-1], pdf, 'o-', ms=5, label='cos')\n",
    "\n",
    "# rect signal with amplitude 1.5\n",
    "x = np.cos(1 * 2*np.pi/Ns*np.arange(0, Ns))\n",
    "x[x >= 0] = +1.5\n",
    "x[x < 0] = -1.5\n",
    "pdf, edges = np.histogram(x, bins=200, density=False)\n",
    "plt.plot(edges[:-1], pdf, 'o-', ms=5, label='rect')\n",
    "\n",
    "plt.ylim(0, 500)\n",
    "plt.xlabel(r'$\\theta$')\n",
    "plt.ylabel(r'histogram($\\theta$)')\n",
    "plt.title('frequency (HÃ¤ufigkeit) of the signal amplitudes within 200 bins')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# We should think about:\n",
    "\n",
    "# what happens if we apply a DC component to the cos and rect signal,\n",
    "# e.g. x += 1\n",
    "\n",
    "# we should able to predict the green histogram values exactly, how should\n",
    "# plt.ylim(0, ???) altered to plot the histogram for the rect more nicely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Example: Higher-Order Ensemble Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two random processes based on normal distribution\n",
    "Ns = 2**10  # number of sample functions at certain time instant k\n",
    "Nt = 1  # number of time steps per sample function\n",
    "np.random.seed(1)\n",
    "\n",
    "# 1st process:\n",
    "locx, scalex = 1, 3\n",
    "x = np.random.normal(loc=locx, scale=scalex, size=[Ns, Nt])\n",
    "\n",
    "# 2nd process:\n",
    "locy, scaley = 2, 4\n",
    "y = np.random.normal(loc=locy, scale=scaley, size=[Ns, Nt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crosspower = np.mean(x * y)\n",
    "covariance = np.mean((x-np.mean(x)) * (y-np.mean(y)))\n",
    "rho = np.mean((x-np.mean(x))/np.std(x) * (y-np.mean(y))/np.std(y))\n",
    "print('crosspower = %4.3f, covariance = %4.3f,  correlation coefficient rho = %4.3f' %\n",
    "      (crosspower, covariance, rho))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensemble Average vs. Temporal Average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create random process based on normal distribution\n",
    "Ns = 4000  # number of sample functions\n",
    "Nt = 16000  # number of time steps per sample function, 1s for 16kHz sampling\n",
    "np.random.seed(1)\n",
    "\n",
    "loc, scale = 5, 3  # mu, sigma\n",
    "x = np.random.normal(loc=loc, scale=scale, size=[Ns, Nt])\n",
    "\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(x[:, 0])\n",
    "plt.xlabel('process index / sample function n')\n",
    "plt.ylabel(r'x$_n$[k=0]')\n",
    "plt.title('many sample functions for fixed time')\n",
    "\n",
    "# check these three cases, the plots nicely show the concepts of ensemble\n",
    "# averages and temporal average, make sure that you understand this with the\n",
    "# cos-like patterns either over sample functions or over time\n",
    "case_str = 'x'  # simulate an ergodic process, i.e. ensemble = temporal average\n",
    "#case_str = 'cosn'  # simulate an non-stationary process by changing the mean\n",
    "#case_str = 'cosk'\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "if case_str == 'x':  # use x directly\n",
    "    plt.plot(x[0, :])\n",
    "    plt.xlabel('time index k')\n",
    "    plt.ylabel(r'x$_{n=0}$[k]')\n",
    "    plt.title('one sample function over time')\n",
    "elif case_str == 'cosn':  # add cosine over sample functions, fixed time\n",
    "    tmp = 2*np.cos(2 * 2*np.pi/Ns * np.arange(0, Ns)) + 5\n",
    "    x = x + np.transpose(np.tile(tmp, (Nt, 1)))\n",
    "    plt.plot(x[:, 0])\n",
    "    plt.xlabel('process index / sample function n')\n",
    "    plt.ylabel(r'x$_n$[k=0]')\n",
    "    plt.title('add cos() over sample function entries')\n",
    "elif case_str == 'cosk':  # add cosine over time, fixed sample function\n",
    "    tmp = 2*np.cos(2 * 2*np.pi/Nt * np.arange(0, Nt)) + 5\n",
    "    x = x + np.tile(tmp, (Ns, 1))\n",
    "    plt.plot(x[0, :])\n",
    "    plt.xlabel('time index k')\n",
    "    plt.ylabel(r'x$_{n=0}$[k]')\n",
    "    plt.title('add cos() over time')\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "plt.subplot(3, 1, 1)\n",
    "plt.plot(np.mean(x, axis=0), label='ensemble average for fixed time instance')\n",
    "plt.plot(np.mean(x, axis=1), label='temporal average for fixed sample function')\n",
    "plt.plot([0, Nt], [loc, loc])\n",
    "plt.legend()\n",
    "plt.title(r'linear mean $E\\{x\\} = \\mu$ of random process')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 2)\n",
    "plt.plot(np.var(x, axis=0))\n",
    "plt.plot(np.var(x, axis=1))\n",
    "plt.plot([0, Nt], [scale**2, scale**2])\n",
    "plt.title('variance  $E\\{(x -E\\{x\\} )^2\\} = \\sigma^2$ of random process')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(3, 1, 3)\n",
    "plt.plot(np.mean(x**2, axis=0))\n",
    "plt.plot(np.mean(x**2, axis=1))\n",
    "plt.plot([0, Nt], [loc**2+scale**2, loc**2+scale**2])\n",
    "plt.title('quadratic mean $E\\{x^2\\} = \\mu^2+\\sigma^2$  of random process')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Higher-Order Temporal Averages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create two random processes based on normal distribution\n",
    "Ns = 1  # number of sample functions at certain time instant k\n",
    "Nt = 2**7  # number of time steps per sample function\n",
    "np.random.seed(1)\n",
    "\n",
    "# 1st process:\n",
    "locx, scalex = 1, 3\n",
    "x = np.random.normal(loc=locx, scale=scalex, size=[Ns, Nt])\n",
    "\n",
    "# 2nd process:\n",
    "locy, scaley = 2, 4\n",
    "y = np.random.normal(loc=locy, scale=scaley, size=[Ns, Nt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Auto Correlation Function (ACF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :], x[0, :])\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'Auto Correlation Function $\\varphi_{xx}[\\kappa]$')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :], y[0, :])\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'Auto Correlation Function $\\varphi_{yy}[\\kappa]$')\n",
    "plt.grid(True)\n",
    "\n",
    "# check the axial symmetry, why is the peak always at kappa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Correlation Function (CCF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :], y[0, :])\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'Cross Correlation Function $\\varphi_{xy}[\\kappa]=\\phi_{yx}[-\\kappa]$')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :], x[0, :])\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'Cross Correlation Function $\\varphi_{yx}[\\kappa]=\\phi_{xy}[-\\kappa]$')\n",
    "plt.grid(True)\n",
    "\n",
    "# check the mirrored versions and how they related wrt kappa, x,y-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Auto Covariance Function\n",
    "\n",
    "typically no symbol in equations and no abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :]-np.mean(x[0, :]), x[0, :]-np.mean(x[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'AutoCov$_{xx}[\\kappa]$')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :]-np.mean(y[0, :]), y[0, :]-np.mean(y[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'AutoCov$_{yy}[\\kappa]$')\n",
    "plt.grid(True)\n",
    "\n",
    "# check the axial symmetry, why is the peak always at kappa=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross Covariance Function\n",
    "\n",
    "typically no symbol in equations and no abbreviation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 3))\n",
    "plt.subplot(1, 2, 1)\n",
    "kappa, ccf = my_xcorr(x[0, :]-np.mean(x[0, :]), y[0, :]-np.mean(y[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'CrossCov$_{xy}[\\kappa]$=CrossCov$_{yx}[-\\kappa]$')\n",
    "plt.grid(True)\n",
    "plt.subplot(1, 2, 2)\n",
    "kappa, ccf = my_xcorr(y[0, :]-np.mean(y[0, :]), x[0, :]-np.mean(x[0, :]))\n",
    "plt.stem(kappa, ccf, basefmt='C0:', use_line_collection=True)\n",
    "plt.xlabel(r'$\\kappa$')\n",
    "plt.title(r'CrossCov$_{yx}[\\kappa]$=CrossCov$_{xy}[-\\kappa]$')\n",
    "plt.grid(True)\n",
    "\n",
    "# check the mirrored versions and how they related wrt kappa, x,y-sequence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Copyright**\n",
    "\n",
    "The notebooks are provided as [Open Educational Resources](https://en.wikipedia.org/wiki/Open_educational_resources). Feel free to use the notebooks for your own purposes. The text is licensed under [Creative Commons Attribution 4.0](https://creativecommons.org/licenses/by/4.0/), the code of the IPython examples under the [MIT license](https://opensource.org/licenses/MIT). Please attribute the work as follows: *Frank Schultz, Digital Signal Processing - A Tutorial Featuring Computational Examples* with the URL https://github.com/spatialaudio/digital-signal-processing-exercises"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mydsp",
   "language": "python",
   "name": "mydsp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
